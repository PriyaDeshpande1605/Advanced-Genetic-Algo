{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNX8BiFSM3jrlmx5AFnc9n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PriyaDeshpande1605/Advanced-Genetic-Algo/blob/main/Rogue_L.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxX8wxTgAuFM"
      },
      "source": [
        "import itertools\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGzYvdTf_BZa"
      },
      "source": [
        "def _get_ngrams(n, text):\n",
        "\n",
        "  ngram_set = set()\n",
        "  text_length = len(text)\n",
        "  max_index_ngram_start = text_length - n\n",
        "  for i in range(max_index_ngram_start + 1):\n",
        "    ngram_set.add(tuple(text[i:i + n]))\n",
        "  return ngram_set\n",
        "\n",
        "def _get_word_ngrams(n, sentences):\n",
        "  \"\"\"Calculates word n-grams for multiple sentences.\n",
        "  \"\"\"\n",
        "  assert len(sentences) > 0\n",
        "  assert n > 0\n",
        "\n",
        "  words = split_into_words(sentences)\n",
        "  return _get_ngrams(n, words)\n",
        "\n",
        "def rouge_n(evaluated_sentences, reference_sentences, n=2):\n",
        "\n",
        "  if len(evaluated_sentences) <= 0 or len(reference_sentences) <= 0:\n",
        "    raise ValueError(\"Collections must contain at least 1 sentence.\")\n",
        "\n",
        "  evaluated_ngrams = _get_word_ngrams(n, evaluated_sentences)\n",
        "  reference_ngrams = _get_word_ngrams(n, reference_sentences)\n",
        "  reference_count = len(reference_ngrams)\n",
        "  evaluated_count = len(evaluated_ngrams)\n",
        "\n",
        "  # Gets the overlapping ngrams between evaluated and reference\n",
        "  overlapping_ngrams = evaluated_ngrams.intersection(reference_ngrams)\n",
        "  overlapping_count = len(overlapping_ngrams)\n",
        "\n",
        "  # Handle edge case. This isn't mathematically correct, but it's good enough\n",
        "  if evaluated_count == 0:\n",
        "    precision = 0.0\n",
        "  else:\n",
        "    precision = overlapping_count / evaluated_count\n",
        "\n",
        "  if reference_count == 0:\n",
        "    recall = 0.0\n",
        "  else:\n",
        "    recall = overlapping_count / reference_count\n",
        "\n",
        "  f1_score = 2.0 * ((precision * recall) / (precision + recall + 1e-8))\n",
        "\n",
        "  # return overlapping_count / reference_count\n",
        "  return f1_score\n",
        "\n",
        "def len_lcs(x, y):\n",
        "\n",
        "  n, m = len(x), len(y)\n",
        "  table = dict()\n",
        "  for i in range(n + 1):\n",
        "    for j in range(m + 1):\n",
        "      if i == 0 or j == 0:\n",
        "        table[i, j] = 0\n",
        "      elif x[i - 1] == y[j - 1]:\n",
        "        table[i, j] = table[i - 1, j - 1] + 1\n",
        "      else:\n",
        "        table[i, j] = max(table[i - 1, j], table[i, j - 1])\n",
        "  return table[n,m]\n",
        "\n",
        "\n",
        "def split_into_words(sentences):\n",
        "  \"\"\"Splits multiple sentences into words and flattens the result\"\"\"\n",
        "  return list(sentences.split(\" \"))\n",
        "\n",
        "\n",
        "def rogue_l( candidate, references  ):\n",
        "  lcs = len_lcs ( candidate, references )\n",
        "  len_x = len(candidate)\n",
        "  len_y = len(references)\n",
        "\n",
        "  recall = lcs / len_y\n",
        "  precision = lcs / len_x\n",
        "  beta = precision/ (recall + 1e-12)\n",
        "  numerator = (1 + (beta ** 2 ) )* (  precision * recall )\n",
        "  denominator = ( precision* ( beta ** 2 ) + recall  ) + 1e-8\n",
        "  f1_score = numerator/ denominator\n",
        "  return f1_score\n",
        "\n",
        "def average_rouge ( candidate, references ):\n",
        "  rouge_1 = rouge_n( candidate, references, 1 )\n",
        "  rouge_2 = rouge_n( candidate, references, 2 )\n",
        "  rouge_lcs = rogue_l( split_into_words(candidate), split_into_words(references) )\n",
        "  avg_rouge = (rouge_1+rouge_2+rouge_lcs)/3\n",
        "  print(\"rouge_1:\", rouge_1)\n",
        "  print(\"rouge_2:\", rouge_2)\n",
        "  print(\"rouge_lcs:\", rouge_lcs)\n",
        "  print(\"average:\" ,avg_rouge)\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6nsRHKI_KE-",
        "outputId": "685b2861-46b8-4e17-97c1-b925b8854ef7"
      },
      "source": [
        "x = \"The quick brown fox jumped over the wall\"\n",
        "y = \"The fast black dumb dog and fox jumped into the wall\"\n",
        "x_words = split_into_words(x)\n",
        "y_words = split_into_words(y)\n",
        "print(x_words)\n",
        "lcs = len_lcs(x_words,y_words)\n",
        "average_rouge(x, y )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'wall']\n",
            "rouge_1: 0.5263157845983379\n",
            "rouge_2: 0.23529411280276827\n",
            "rouge_lcs: 0.5018990745235409\n",
            "average: 0.4211696573082157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKLJJaCl_ZPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "841b3967-1d35-4ac7-d64b-fa4f4413fe47"
      },
      "source": [
        "import itertools\n",
        "import numpy as np\n",
        "\n",
        "def _get_ngrams(n, text):\n",
        "\n",
        "  ngram_set = set()\n",
        "  text_length = len(text)\n",
        "  max_index_ngram_start = text_length - n\n",
        "  for i in range(max_index_ngram_start + 1):\n",
        "    ngram_set.add(tuple(text[i:i + n]))\n",
        "  return ngram_set\n",
        "\n",
        "def _get_word_ngrams(n, sentences):\n",
        "  \"\"\"Calculates word n-grams for multiple sentences.\n",
        "  \"\"\"\n",
        "  assert len(sentences) > 0\n",
        "  assert n > 0\n",
        "\n",
        "  words = split_into_words(sentences)\n",
        "  return _get_ngrams(n, words)\n",
        "\n",
        "def rouge_n(evaluated_sentences, reference_sentences, n=2):\n",
        "\n",
        "  if len(evaluated_sentences) <= 0 or len(reference_sentences) <= 0:\n",
        "    raise ValueError(\"Collections must contain at least 1 sentence.\")\n",
        "\n",
        "  evaluated_ngrams = _get_word_ngrams(n, evaluated_sentences)\n",
        "  reference_ngrams = _get_word_ngrams(n, reference_sentences)\n",
        "  reference_count = len(reference_ngrams)\n",
        "  evaluated_count = len(evaluated_ngrams)\n",
        "\n",
        "  # Gets the overlapping ngrams between evaluated and reference\n",
        "  overlapping_ngrams = evaluated_ngrams.intersection(reference_ngrams)\n",
        "  overlapping_count = len(overlapping_ngrams)\n",
        "\n",
        "  # Handle edge case. This isn't mathematically correct, but it's good enough\n",
        "  if evaluated_count == 0:\n",
        "    precision = 0.0\n",
        "  else:\n",
        "    precision = overlapping_count / evaluated_count\n",
        "\n",
        "  if reference_count == 0:\n",
        "    recall = 0.0\n",
        "  else:\n",
        "    recall = overlapping_count / reference_count\n",
        "\n",
        "  f1_score = 2.0 * ((precision * recall) / (precision + recall + 1e-8))\n",
        "\n",
        "  # return overlapping_count / reference_count\n",
        "  return f1_score\n",
        "\n",
        "def len_lcs(x, y):\n",
        "\n",
        "  n, m = len(x), len(y)\n",
        "  table = dict()\n",
        "  for i in range(n + 1):\n",
        "    for j in range(m + 1):\n",
        "      if i == 0 or j == 0:\n",
        "        table[i, j] = 0\n",
        "      elif x[i - 1] == y[j - 1]:\n",
        "        table[i, j] = table[i - 1, j - 1] + 1\n",
        "      else:\n",
        "        table[i, j] = max(table[i - 1, j], table[i, j - 1])\n",
        "  return table[n,m]\n",
        "\n",
        "\n",
        "def split_into_words(sentences):\n",
        "  \"\"\"Splits multiple sentences into words and flattens the result\"\"\"\n",
        "  return list(sentences.split(\" \"))\n",
        "\n",
        "\n",
        "def rogue_l( candidate, references  ):\n",
        "  lcs = len_lcs ( candidate, references )\n",
        "  len_x = len(candidate)\n",
        "  len_y = len(references)\n",
        "\n",
        "  recall = lcs / len_y\n",
        "  precision = lcs / len_x\n",
        "  beta = precision/ (recall + 1e-12)\n",
        "  numerator = (1 + (beta ** 2 ) )* (  precision * recall )\n",
        "  denominator = ( precision* ( beta ** 2 ) + recall  ) + 1e-8\n",
        "  f1_score = numerator/ denominator\n",
        "  return f1_score\n",
        "\n",
        "def average_rouge ( candidate, references ):\n",
        "  rouge_1 = rouge_n( candidate, references, 1 )\n",
        "  rouge_2 = rouge_n( candidate, references, 2 )\n",
        "  rouge_lcs = rogue_l( split_into_words(candidate), split_into_words(references) )\n",
        "  avg_rouge = (rouge_1+rouge_2+rouge_lcs)/3\n",
        "  print(\"rouge_1:\", rouge_1)\n",
        "  print(\"rouge_2:\", rouge_2)\n",
        "  print(\"rouge_lcs:\", rouge_lcs)\n",
        "  print(\"average:\" ,avg_rouge)\n",
        "\n",
        "def main():\n",
        "\tx = \"The quick brown fox jumped over the wall\"\n",
        "\ty = \"The fast black dog and fox jumped into the wall\"\n",
        "\tx_words = split_into_words(x)\n",
        "\ty_words = split_into_words(y)\n",
        "\tprint(x_words)\n",
        "\tlcs = len_lcs(x_words,y_words)\n",
        "\taverage_rouge(x, y )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'wall']\n",
            "rouge_1: 0.555555550617284\n",
            "rouge_2: 0.24999999507812506\n",
            "rouge_lcs: 0.5423280386552448\n",
            "average: 0.4492945281168847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJlINMPILexN"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}